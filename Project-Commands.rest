.. contents:: `Supported task commands`
   :depth: 1
   :local:

archive.targz_extract
^^^^^^^^^^^^^^^^^^^^^

``archive.targz_extract`` extracts files from a gzipped tarball.

.. code:: yaml

   - command: archive.targz_extract
     params:
       path: "jstests.tgz"
       destination: "src/jstestfuzz"

Parameters:
 
-  ``path``: the path to the tarball 
-  ``destination``: the target directory 
-  ``exclude_files``: a list of filename `blobs <https://golang.org/pkg/path/filepath/#Match>`__ to exclude

archive.targz_pack
^^^^^^^^^^^^^^^^^^

``archive.targz_pack`` creates a gzipped tarball.

.. code:: yaml

   - command: archive.targz_pack
     params:
       target: "jstests.tgz"
       source_dir: "src/jstestfuzz"
       include:
         - "out/*.js"

Parameters:
 
-  ``target``: the tgz file that will be created 
- ``source_dir``: the directory to compress 
-  ``include``: a list of filename blobs to include 
-  ``exclude_files``: a list of filename `blobs <https://golang.org/pkg/path/filepath/#Match>`__ to exclude

attach.artifacts
^^^^^^^^^^^^^^^^

This command allows users to add files to the “Files” section of the
task page without using the ``s3.put`` command. Suppose you uploaded a
file to https://example.com/this-is-my-file in your task. For instance,
you might be using boto in a Python script. You can then add a link to
the Files element on the task page by:

.. code:: yaml

   - command: attach.artifacts
     params:
       files:
         - example.json

.. code:: json

   [
     {
       "name": "my-file",
       "link": "https://example.com/this-is-my-file",
       "visibility": "public"
     }
   ]

An additional “ignore_for_fetch” parameter controls whether the file
will be downloaded when spawning a host from the spawn link on a test
page.

attach.results
^^^^^^^^^^^^^^

This command parses results in Evergreen’s JSON test result format and
posts them to the API server.

The format is as follows:

.. code:: json

   {
       "results":[
       {
           "status":"pass",
               "test_file":"test_1",
               "exit_code":0,
               "elapsed":0.32200002670288086, //end-start
               "start":1398782500.359, //epoch_time
               "end":1398782500.681 //epoch_time
       },
       {
           "etc":"..."
       },
       ]
   }

.. code:: yaml

   - command: attach.results
     params:
       file_location: src/report.json

Parameters:
 
-  ``file_location``: a .json file to parse and upload

attach.xunit_results
^^^^^^^^^^^^^^^^^^^^

This command parses results in the XUnit format and posts them to the
API server.

.. code:: yaml

   - command: attach.xunit_results
     params:
       file: src/results.xml

Parameters:
 
-  ``file``: a .xml file to parse and upload. A filepath glob can also be supplied to collect results from multiple files.

expansions.update
^^^^^^^^^^^^^^^^^

``expansions.update`` updates the task’s expansions at runtime.

.. code:: yaml

   - command: expansions.update
     params:
       ignore_missing_file: true
       file: src/ec2_artifacts.yml

Parameters:
 
-  ``updates``: key-value pairs for updating the task’s parameters 
-  ``file``: filename for a yaml file containing expansion updates 
-  ``ignore_missing_file``: do not error if the file is missing

expansions.write
^^^^^^^^^^^^^^^^

``expansions.write`` writes the task’s expansions to a file

.. code:: yaml

   - command: expansions.write
     params:
       file: expansions.yaml

Parameters:
 
-  ``file``: filename to write expansions to 
- ``redacted``: include redacted project variables, defaults to false

generate.tasks
^^^^^^^^^^^^^^

This command creates functions, tasks, and variants from a user-provided
JSON file. 
-  generate.tasks cannot be called more than once per static
variant. 
-  generate.tasks cannot be called from a dynamic variant. 
- 
generate.tasks cannot redefine functions, tasks, or variants.
generate.tasks may only append new functions, tasks, and variants. It is
a validation error to modify an existing static or dynamic function,
task, or variant, or to define one twice in the JSON document passed to
the command. It is legal to specify a variant multiple times in order to
add additional tasks to the variant, as long as no other variant
metadata is changed. 
-  The calls to generate.tasks may not in aggregate
in a single version generate more than 100 variants or more than 1000
tasks.

.. code:: yaml

   - command: generate.tasks
     params:
       files:
         - example.json

Parameters:
 
-  ``files``: the JSON file to generate tasks from

.. code:: json

   {
       "functions": {
           "echo-hi": {
               "command": "shell.exec",
               "params": {
                   "script": "echo \"hi\"\n"
               }
           }
       },
       "tasks": [
           {
               "commands": [
                   {
                       "command": "git.get_project",
                       "params": {
                           "directory": "src"
                       }
                   },
                   {
                       "func": "echo-hi"
                   }
               ],
               "name": "test"
           }
       ],
       "buildvariants": [
           {
               "tasks": [
                   {
                       "name": "test"
                   }
               ],
               "display_name": "Ubuntu 16.04",
               "run_on": [
                   "ubuntu1604-test"
               ],
               "name": "ubuntu1604"
           }
       ]
   }

git.get_project
^^^^^^^^^^^^^^^

This command clones the tracked project repository into a given
directory, and checks out the revision associated with the task. Also
applies patches to the source after cloning it, if the task was created
by a patch submission.

NOTE: this command currently only supports clone over SSH. Make sure
your GitHub ssh keys are set up in your target distros.

.. code:: yaml

   - command: git.get_project
     params:
       directory: src
       revisions:
         example: ${example_rev}

Parameters:
 
-  ``dir``: the directory to clone into
-  ``revisions``: for each module include revision as ``<module_name> : ${<module_name>_rev}``

The parameters for each module are: 

-  ``name``: the name of the module
-   ``repo``: the repo of the module
-   ``prefix``: the path to the modules, if applicable
-   ``ref``: must be a commit hash, takes precedence over the ``branch`` parameter if both specified
-   ``branch``: must be the name of branch, commit hashes `are not accepted`
  
gotest.parse_files
^^^^^^^^^^^^^^^^^^

This command parses Go test results and sends them to the API server. It
accepts files generated by saving the output of the ``go test -v``
command to a file.

E.g. In a preceding shell.exec command, run
``go test -v > result.suite``

.. code:: yaml

   - command: gotest.parse_files
     params:
       files: ["src/*.suite"]

Parameters:
 
-  ``files``: a list of files (or blobs) to parse and upload

host.create
^^^^^^^^^^^

``host.create`` starts a host from a task.

.. code:: yaml

   - command: host.create
     params:
       provider: ec2
       distro: rhel70-small

Parameters:
 
-  ``ami`` - EC2 AMI to start. Must set ``ami`` or ``distro`` but must not set both. 
-  ``aws_access_key_id`` - AWS access key ID. May set to use a non-default account. Must set if ``aws_secret_access_key`` is set. 
-  ``aws_secret_access_key`` - AWS secret key. May set to use a non-default account. Must set if ``aws_access_key_id`` is set. 
-  ``distro`` - Evergreen distro to start. Must set ``ami`` or ``distro`` but must not set both. 
- ``ebs_block_device`` - list of the following parameters: 
- ``device_name`` - name of EBS device 
-  ``ebs_iops`` - EBS provisioned IOPS. 
-  ``ebs_size`` - Size of EBS volume in GB. 
-  ``ebs_snapshot_id`` - EBS snapshot ID to mount. 
-  ``instance_type`` - EC2 instance type. Must set if ``ami`` is set. May set if ``distro`` is set, which will override the value from the distro configuration. 
-  ``key_name`` - EC2 Key name. Must set if ``aws_access_key_id`` or ``aws_secret_access_key`` is set. Must not set otherwise. 
-  ``num_hosts`` - Number of hosts to start, 1 <= ``num_hosts`` <= 10. Defaults to 1. 
-  ``provider`` - Cloud provider. Must set ``ec2.`` We intend to support other providers as future work. 
-  ``region`` - EC2 region. Default is the same as Evergreen’s default. 
-  ``retries`` - How many times Evergreen should try to create this host in EC2 before giving up. Evergreen will wait 1 minute between retries. 
-  ``scope`` - When Evergreen will tear down the host, i.e., when either the task or build is finished. Must be either ``task`` or ``build``. Defaults to ``task`` if not set. 
- ``security_group_ids`` - List of security groups. Must set if ``ami`` is set. May set if ``distro`` is set, which will override the value from the distro configuration. 
-  ``spot`` - Spawn a spot instance if ``true.`` Defaults to ``false``. 
-  ``subnet_id`` - Subnet ID for the VPC. Must be set if ``ami`` is set. 
-  ``timeout_setup_secs`` - Stop waiting for hosts to be ready when spawning. Must be 60 <= ``timeout_setup_secs`` <= 3600 (1 hour). Default to 600 (10 minutes). 
- ``timeout_teardown_secs`` - Even if the task or build has not finished, tear down this host after this many seconds. Must be 60 <= ``timeout_teardown_secs`` <= 604800 (7 days). Default to 21600 (6 hours). 
-  ``userdata_file`` - Path to file to load as EC2 user data on boot. May set if ``distro`` is set, which will override the value from the distro configuration. 
-  ``vpc_id`` - EC2 VPC. Must set if ``ami`` is set. May set if ``distro`` is set, which will override the value from the distro configuration.

Required IAM Policies for ``host.create``
-----------------------------------------

If creating an Elastic Compute Cloud (EC2) instance using an Amazon
Machine Image (AMI), then the user must specify the list of security
groups the EC2 instance inherits, the subnet ID, and the VPC ID. The IAM
policy statement for the user creating the EC2 instance *must* have the
following read-only permissions:

-  ``ec2:DescribeImages``
-  ``ec2:DescribeSecurityGroups``
-  ``ec2:DescribeSubnets``
-  ``ec2:DescribeVpcs``
-  ``pricing:GetProducts``

If the policy statement does not honor these permissions, then the
instance fails to create.

Refer to `IAM Policies for Amazon
EC2 <https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-policies-for-amazon-ec2.html>`__
for more information.

Checking SSH Availability for Spawn Hosts
-----------------------------------------

Certain instances require more time for SSH access to become available.
If the user plans to execute commands on the remote host, then waiting
for SSH access to become available is mandatory. Below is an Evergreen
function that probes for SSH connectivity:

.. code:: yaml

   functions:
     # Check SSH availability
     ssh-ready:
       command: shell.exec
       params:
         script: |
           user=${admin_user_name}
           hostname=$(tr -d '"[]{}' < buildhost-configuration/hosts.yml | cut -d , -f 1 | awk -F : '{print $2}')
           identity_file=~/.ssh/mcipacker.pem

           attempts=0
           connection_attempts=${connection_attempts|25}

           # Check for remote connectivity
           while ! ssh \
             -i "$identity_file" \
             -o ConnectTimeout=10 \
             -o ForwardAgent=yes \
             -o IdentitiesOnly=yes \
             -o StrictHostKeyChecking=no \
             "$(printf "%s@%s" "$user" "$hostname")" \
             exit 2> /dev/null
           do
             [ "$attempts" -ge "$connection_attempts" ] && exit 1
             ((attempts++))
             printf "SSH connection attempt %d/%d failed. Retrying...\n" "$attempts" "$connection_attempts"
             # sleep for Permission denied (publickey) errors
             sleep 10
           done
         shell: bash

   tasks:
     - name: test
       commands:
         - command: host.create
           params:
             ami: ${ami}
             aws_access_key_id: ${aws_access_key_id}
             aws_secret_access_key: ${aws_secret_access_key}
             instance_type: ${instance_type|m3.medium}
             key_name: ${key_name}
             provider: ec2
             security_group_ids:
               - ${security_group_id}
             subnet_id: ${subnet_id}
             vpc_id: ${vpc_id}
         - command: host.list
           params:
             num_hosts: 1
             path: buildhost-configuration/hosts.yml
             timeout_seconds: 600
             wait: true
         - func: ssh-ready
         - func: other-tasks

host.list
^^^^^^^^^

``host.list`` gets information about hosts created by ``host.create``.

.. code:: yaml

   - command: host.list
     params:
       wait: true
       timeout_seconds: 300
       num_hosts: 1

Parameters:
 
-  ``num_hosts`` - if ``wait`` is set, the number of hosts to wait to be running before the command returns 
-  ``path`` - path to file to write host info to 
-  ``silent`` - if true, do not log host info to the task logs 
-  ``timeout_seconds`` - time to wait for ``num_hosts`` to be running 
-  ``wait`` - if set, wait ``timeout_seconds`` for ``num_hosts`` to be running

If the ``path`` directive is specified, then the contents of the file
contain a JSON formatted list of objects. Each object contains the
following keys:

-  ``dns_name``: The FQDN of the EC2 instance
-  ``instance_id``: The unique identifier of the EC2 instance

.. code:: json

   [
       {
           "dns_name": "ec2-52-91-50-29.compute-1.amazonaws.com",
           "instance_id": "i-096d6766961314cd5"
       }
   ]

manifest.load
^^^^^^^^^^^^^

``manifest.load`` updates the project’s expansions with the manifest, if
it exists.

.. code:: yaml

   - command: manifest.load

s3.get
^^^^^^

``s3.get`` downloads a file from Amazon s3.

.. code:: yaml

   - command: s3.get
     params:
       aws_key: ${aws_key}
       aws_secret: ${aws_secret}
       remote_file: ${mongo_binaries}
       bucket: mciuploads
       local_file: src/mongo-binaries.tgz

Parameters:
 
-  ``aws_key``: your AWS key (use expansions to keep this a secret) 
-  ``aws_secret``: your AWS secret (use expansions to keep this a secret) 
-  ``local_file``: the local file to save, do not use with ``extract_to`` 
-  ``extract_to``: the local directory to extract to, do not use with ``local_file`` 
-  ``remote_file``: the ec2 path to get the file from 
-  ``bucket``: the ec2 bucket to use 
-  ``build_variants``: list of buildvariants to run the command for, if missing/empty will run for all

s3.put
^^^^^^

This command uploads a file to Amazon s3, for use in later tasks or
distribution.

.. code:: yaml

   - command: s3.put
     params:
       aws_key: ${aws_key}
       aws_secret: ${aws_secret}
       local_file: src/mongodb-binaries.tgz
       remote_file: mongodb-mongo-master/${build_variant}/${revision}/binaries/mongo-${build_id}.${ext|tgz}
       bucket: mciuploads
       permissions: public-read
       content_type: ${content_type|application/x-gzip}
       display_name: Binaries

Parameters:
 
-  ``aws_key``: your AWS key (use expansions to keep this a secret) 
-  ``aws_secret``: your AWS secret (use expansions to keep this a secret) 
-  ``local_file``: the local file to post
-  ``remote_file``: the ec2 path to post the file to
-  ``bucket``: the ec2 bucket to use 
- ``permissions``: the ec2 permissions string to upload with 
- ``content_type``: the MIME type of the file 
-  ``optional``: boolean to indicate if failure to find or upload this file will result in a task failure. Not compatible with local_files_include_filter. 
- ``display_name``: the display string for the file in the Evergreen UI 
- ``local_files_include_filter``: used in place of local_file, an array of gitignore file globs. All files that are matched - ones that would be ignored by gitignore - are included in the put.

s3.put with multiple files
^^^^^^^^^^^^^^^^^^^^^^^^^^

Using the s3.put command in this uploads multiple files to an s3 bucket.

.. code:: yaml

   - command: s3.put
     params:
       aws_key: ${aws_key}
       aws_secret: ${aws_secret}
       local_files_include_filter:
         - slow_tests/coverage/*.tgz
         - fast_tests/coverage/*.tgz
       remote_file: mongodb-mongo-master/test_coverage-
       bucket: mciuploads
       permissions: public-read
       content_type: ${content_type|application/x-gzip}
       display_name: coverage-

Each file is displayed in evergreen as the file’s name prefixed with the
``display_name`` field. Each file is uploaded to a path made of the
local file’s name, in this case whatever matches the ``*.tgz``, prefixed
with what is set as the ``remote_file`` field. The filter uses the same
specification as gitignore when matching files. In this way, all files
that would be marked to be ignored in a gitignore containing the lines
``slow_tests/coverate/*.tgz`` and ``fast_tests/coverate/*.tgz`` are
uploaded to the s3 bucket.

s3Copy.copy
^^^^^^^^^^^

``s3Copy.copy`` copies files from one s3 location to another

.. code:: yaml

   - command: s3Copy.copy
     params:
       aws_key: ${aws_key}
       aws_secret: ${aws_secret}
       s3_copy_files:
           - {'source': {'path': '${push_path}-STAGE/${push_name}/mongodb-${push_name}-${push_arch}-${suffix}-${task_id}.${ext|tgz}', 'bucket': 'build-push-testing'},
              'destination': {'path': '${push_path}/mongodb-${push_name}-${push_arch}-${suffix}.${ext|tgz}', 'bucket': '${push_bucket}'}}

Parameters:
 
-  ``aws_key``: your AWS key (use expansions to keep this a secret) 
-  ``aws_secret``: your AWS secret (use expansions to keep this a secret) 
-  ``s3_copy_files``: a map of ``source`` (``bucket`` and ``path``), ``destination``, ``buildvariants`` (a list of strings), ``display_name``, and ``optional`` (suppresses errors)

shell.exec
^^^^^^^^^^

This command runs a shell script.

.. code:: yaml

   - command: shell.exec
     params:
       working_dir: src
       script: |
         echo "this is a 2nd command in the function!"
         ls

Parameters:
 
-  ``script``: the script to run 
-  ``working_dir``: the directory to execute the shell script in 
-  ``background``: if set to true, does not wait for the script to exit before running the next commands 
-  ``silent``: if set to true, does not log any shell output during execution; useful to avoid leaking sensitive info 
- ``continue_on_err``: if set to true, causes command to exit with success regardless of the script’s exit code 
-  ``system_log``: if set to true, the script’s output will be written to the task’s system logs, instead of inline with logs from the test execution. 
-  ``shell``: shell to use. Defaults to sh if not set. Note that this is usually bash but is dash on Debian, so it’s good to explicitly pass this parameter 
- ``ignore_standard_out``: if true, discards output sent to stdout 
- ``ignore_standard_error``: if true, discards output sent to stderr 
- ``redirect_standard_error_to_output``: if true, sends stderr to stdout. Can be used to synchronize these 2 streams

subprocess.exec
^^^^^^^^^^^^^^^

The subprocess.exec command runs a shell command.

.. code:: yaml

   - command: subprocess.exec
     params:
       working_dir: "src"
       env:
         FOO: bar
         BAZ: qux
       binary: "command"
       args:
         - "arg1"
         - "arg2"

Parameters:
 
-  ``binary``: a binary to run 
-  ``args``: a list of arguments to the binary 
-  ``env``: a slice of environment variables and their values 
-  ``command``: a command string (cannot use with ``binary`` or ``args``) 
-  ``background``: if true, immediately return to caller 
-  ``silent``: do not log output of command 
-  ``system_log``: write output to system logs instead of task logs 
-  ``working_dir``: working directory to start shell in 
-  ``ignore_standard_out``: if true, do not log standard out 
-  ``ignore_standard_error``: if true, do not log standard error 
-  ``redirect_standard_error_to_output``: if true, redirect standard error to standard out 
-  ``continue_on_error``: if true, do not mark task as failed if command fails

timeout.update
^^^^^^^^^^^^^^

This command sets ``exec_timeout_secs`` or ``timeout_secs`` of a task
from within that task.

.. code:: yaml

         - command: timeout.update
           params:
             exec_timeout_secs: ${my_exec_timeout_secs}
             timeout_secs: ${my_timeout_secs}

Parameters:
 
-  ``exec_timeout_secs``: set ``exec_timeout_secs`` for the task, which is the maximum amount of time the task may run. May be int, string, or expansion 
-  ``timeout_secs``: set ``timeout_secs`` for the task, which is the maximum amount of time that can elapse without any output on stdout. May be int, string, or expansion

Both parameters are optional. If not set, the task will use the
definition from the project config.
